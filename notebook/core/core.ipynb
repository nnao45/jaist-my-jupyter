{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV,ElasticNetCV\n",
    "from pyentrp import entropy as pyent\n",
    "import EntropyHub as EH\n",
    "import neurokit2 as nk\n",
    "import random\n",
    "import sampen\n",
    "import requests\n",
    "import io\n",
    "import apache_log_parser\n",
    "from pprint import pprint\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import hurst\n",
    "import math\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enet( x_train, y_train, alpha = 1.0, l1_ratio = 0.5) -> ElasticNet:\n",
    "    return ElasticNet(alpha=alpha, l1_ratio=l1_ratio).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enet_loop(x, y, alpha = 1.0, l1_ratio = 0.5, batch_size = 9):\n",
    "    y_pred = pd.DataFrame([])\n",
    "    for index in range(int(x.size))[batch_size:]:\n",
    "        try:\n",
    "            x_train = x[index-batch_size:index]\n",
    "            y_train = y[index-batch_size:index]\n",
    "            x_test = x[index+1].reshape(-1, 1)\n",
    "            enet = compute_enet(x_train, y_train, alpha, l1_ratio)\n",
    "            target_y_pred = enet.predict(x_test)\n",
    "            y_pred = y_pred.append(pd.DataFrame(target_y_pred), ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import hankel\n",
    "from scipy.spatial.distance import pdist\n",
    "from typing import List\n",
    "import sys\n",
    "import math\n",
    "\n",
    "def disten(ser: List[float], m: int = 2, tau: int = 8 , B: int = 512) -> float:\n",
    "    \"\"\"\n",
    "    @param ser: time-series (vector in a column)\n",
    "    @param m: embedding dimension (scalar)\n",
    "    @param tau: time delay (scalar)\n",
    "    @param B: bin number for histogram (scalar)\n",
    "    \"\"\"\n",
    "\n",
    "    # rescaling\n",
    "    rescaled = [y / (max(ser) - min(ser) + sys.float_info.epsilon) for y in [x - min(ser) for x in ser]]\n",
    "\n",
    "    # distance matrix\n",
    "    N = len(rescaled) - (m - 1) * tau\n",
    "    if N < 0:\n",
    "        raise(f\"ser is too short: {len(ser)}\")\n",
    "    ind = hankel(np.arange(1, N+1), np.arange(N, len(rescaled)+1))\n",
    "    rnt = [[rescaled[z-1] for z in y] for y in [x[::tau] for x in ind]]\n",
    "    dv = pdist(rnt, 'chebychev')\n",
    "\n",
    "    # esimating probability density by histogram\n",
    "    num = pd.cut(dv, np.linspace(0, 1, B), include_lowest=True).value_counts().to_numpy()\n",
    "    freq = [x / num.sum() for x in num]\n",
    "\n",
    "    # disten calculation\n",
    "    prepared = [math.log2(y) for y in [x + sys.float_info.epsilon for x in freq]]\n",
    "    return -sum([x * y for (x, y) in zip(prepared, freq)]) / math.log2(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disten_loop(ser: List[float], batch_size = 300) -> List[float]:\n",
    "    return [disten(ser[index:index+batch_size]) for index in range(len(ser[batch_size:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocken(ser, trunk_size) -> List[float]:\n",
    "    past = 0.\n",
    "    results = []\n",
    "    for y in ser:\n",
    "        current_ceiled = math.ceil(y / trunk_size)\n",
    "        past_ceiled = math.ceil(past / trunk_size)\n",
    "        if current_ceiled == past_ceiled-1 | current_ceiled == past_ceiled+1:\n",
    "            current_ceiled = past_ceiled\n",
    "        current_result = current_ceiled * trunk_size\n",
    "        results = results + [current_result]\n",
    "        past = current_result\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampen_loop(ser: List[float], batch_size = 300) -> List[float]:\n",
    "    return [nk.entropy_sample(np.array(ser[index-batch_size:index]))[0] for index in range(len(ser))[batch_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(df: pd.DataFrame)-> np.ndarray:\n",
    "    return np.array(list(itertools.chain.from_iterable(df.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(100)[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed3e3cd7eaae78a028302f8c60b23327bead7311331f61381685cdcdea648c8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
